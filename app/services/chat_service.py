import asyncio
import json
import re
from typing import AsyncGenerator, Dict, Any, Optional, List, Tuple
from uuid import UUID, uuid4
from datetime import datetime, timedelta
import redis.asyncio as aioredis
from sqlalchemy.orm import Session
from sqlalchemy import and_
from fastapi import WebSocket
import logging

# ä¿®æ­£å¯¼å…¥è·¯å¾„
from app.models.chat import ChatSession, ChatMessage
from app.models.user import User
from app.core.ai_engine import AIEngine
from app.db.redis import get_redis
from app.schemas.chat import StreamChunk
from app.config import settings
from app.utils.markdown import escape_markdown, split_code, replace_all
from app.utils.file_handler import extract_file_content
from app.services.code_service import CodeService
from app.services.ai_code_service import AICodeGenerationService
from app.core.code_extractor import CodeExtractor


logger = logging.getLogger(__name__)

class ChatService:
    def __init__(self, db: Session, redis: aioredis.Redis):
        self.db = db
        self.redis = redis
        self.ai_engine = AIEngine()
        self.message_cache = {}  # æ¶ˆæ¯ç¼“å­˜
        self.typing_tasks = {}   # è¾“å…¥çŠ¶æ€ä»»åŠ¡
        self.code_service = CodeService(db)  # ä¼ é€’ db å‚æ•°
        self.ai_code_service = AICodeGenerationService(self.ai_engine, self.code_service)
        
    async def process_message(
        self,
        user_id: UUID,
        message: str,
        model: Optional[str] = None,
        conversation_id: Optional[str] = None,
        system_prompt: Optional[str] = None,
        attachments: Optional[List[str]] = None,
        pass_history: Optional[int] = None
    ) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›AIå“åº”"""
        
        # è·å–ç”¨æˆ·é…ç½®
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            raise ValueError("ç”¨æˆ·ä¸å­˜åœ¨")
        
        # ä½¿ç”¨ç”¨æˆ·åå¥½çš„æ¨¡å‹æˆ–ä¼ å…¥çš„æ¨¡å‹
        model = model or user.preferred_model or settings.DEFAULT_MODEL
        user_preferences = user.preferences or {}
        
        # æ£€æµ‹æ˜¯å¦æ˜¯ä»£ç ç”Ÿæˆè¯·æ±‚
        is_code_generation, script_type = self.ai_code_service.detect_code_generation_intent(message)
        
        if is_code_generation:
            # ä½¿ç”¨æ™ºèƒ½ä»£ç ç”ŸæˆæœåŠ¡
            result = await self.ai_code_service.generate_code_with_ai(
                user_request=message,
                script_type=script_type,
                model=model,
                user_id=str(user_id),
                conversation_id=conversation_id,
                system_prompt=system_prompt
            )
            
            # å¦‚æœæœ‰ cron è¡¨è¾¾å¼å¹¶ä¸”æœ‰å¯æ‰§è¡Œä»£ç ï¼Œè‡ªåŠ¨è®¾ç½®å®šæ—¶ä»»åŠ¡
            if result.get("cron_ready") and user_preferences.get("auto_setup_cron", True):
                cron_result = await self.ai_code_service.setup_cron_job_from_code(
                    code_id=result["cron_ready"]["code_id"],
                    cron_expression=result["cron_ready"]["cron_expression"],
                    user_id=str(user_id),
                    job_name=result["cron_ready"]["suggested_job_name"]
                )
                
                # æ·»åŠ  cron è®¾ç½®ç»“æœåˆ°å“åº”
                if cron_result["success"]:
                    cron_readable = self.ai_code_service.parse_cron_to_human_readable(
                        result["cron_ready"]["cron_expression"]
                    )
                    result["ai_response"] += f"\n\nâœ… å®šæ—¶ä»»åŠ¡å·²è‡ªåŠ¨è®¾ç½®ï¼š{cron_readable}"
                    result["cron_setup"] = cron_result
            
            # æ„å»ºå“åº”
            response = {
                "id": str(uuid4()),
                "conversation_id": conversation_id or str(uuid4()),
                "content": result["ai_response"],
                "model": model,
                "created_at": datetime.utcnow().isoformat(),
                "metadata": result.get("metadata", {}),
                "code_extraction": result.get("code_extraction"),
                "cron_setup": result.get("cron_setup")
            }
            
            return response
        
        # å¦‚æœä¸æ˜¯ä»£ç ç”Ÿæˆè¯·æ±‚ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
        if self._is_code_generation_request(message):
            code_generation_prompt = self._get_code_generation_prompt()
            if system_prompt:
                system_prompt = f"{system_prompt}\n\n{code_generation_prompt}"
            else:
                system_prompt = code_generation_prompt

        # è·å–å†å²è®°å½•ä¼ é€’æ•°é‡
        if pass_history is None:
            pass_history = user.preferences.get("PASS_HISTORY", 3) if user.preferences else 3
        
        # è·å–æˆ–åˆ›å»ºä¼šè¯
        if conversation_id:
            # å°è¯•å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºUUID
            try:
                conv_uuid = UUID(conversation_id)
                conversation = self._get_conversation(user_id, conv_uuid)
            except ValueError:
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„UUIDï¼Œåˆ›å»ºæ–°ä¼šè¯
                conversation = None
                
            if not conversation:
                # åˆ›å»ºæ–°ä¼šè¯
                conversation = self._create_conversation(user_id, model, system_prompt)
        else:
            conversation = self._create_conversation(user_id, model, system_prompt)
        
        # å¤„ç†é™„ä»¶
        if attachments:
            message = await self._process_attachments(attachments, message)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_message = ChatMessage(
            session_id=conversation.id,
            role="user",
            content=message,
            attachments=attachments or []
        )
        self.db.add(user_message)
        self.db.commit()
        
        # è·å–å†å²æ¶ˆæ¯
        history = self._get_conversation_history(
            conversation.id, 
            limit=pass_history if pass_history > 0 else 0
        )
        
        # å‡†å¤‡ç³»ç»Ÿæç¤ºè¯
        if model and "claude" in model.lower():
            final_system_prompt = system_prompt or user.claude_system_prompt or ""
        else:
            final_system_prompt = system_prompt or user.system_prompt or ""
        
        # è·å–å¯ç”¨çš„æ’ä»¶
        enabled_plugins = self._get_enabled_plugins(user)
        
        # è°ƒç”¨AIå¼•æ“
        ai_response = await self.ai_engine.get_completion(
            messages=history,
            model=model,
            system_prompt=final_system_prompt,
            temperature=0.7,  # é»˜è®¤æ¸©åº¦
            max_tokens=None,  # ä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
            plugins=enabled_plugins,
            user_id=str(user_id),
            api_key=self._get_api_key(user, model),
            api_url=self._get_api_url(user, model)
        )
        
        # ä¿å­˜AIå“åº”
        assistant_message = ChatMessage(
            session_id=conversation.id,
            role="assistant",
            content=ai_response["content"],
            model=model,
            message_data={
                "tokens": ai_response.get("usage", {}),
                "finish_reason": ai_response.get("finish_reason")
            }
        )
        self.db.add(assistant_message)
        
        if user_preferences.get("auto_extract_code", True):
            try:
                code_result = await self.code_service.process_ai_response_for_code(
                    ai_response=ai_response["content"],
                    user_id=str(user_id),
                    conversation_id=str(conversation.id),
                    auto_save=user_preferences.get("auto_save_code", True)
                )
                # å¦‚æœæœ‰ä»£ç ï¼Œæ·»åŠ åˆ°å“åº”å…ƒæ•°æ®
                if code_result["has_code"]:
                    if "metadata" not in ai_response:
                        ai_response["metadata"] = {}
                    ai_response["metadata"]["extracted_codes"] = code_result["code_blocks"]
                    
                    # åœ¨å“åº”å†…å®¹åæ·»åŠ ä»£ç æå–é€šçŸ¥
                    if code_result["code_blocks"]:
                        saved_count = len([c for c in code_result["code_blocks"] if c.get("saved")])
                        if saved_count > 0:
                            ai_response["content"] += f"\n\nğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ {saved_count} ä¸ªå¯æ‰§è¡Œä»£ç å—ã€‚" 
            except Exception as e:
                logger.error(f"Code extraction failed: {e}")

        # æ›´æ–°ä¼šè¯ä¿¡æ¯
        conversation.updated_at = datetime.utcnow()
        conversation.message_count = (conversation.message_count or 0) + 2
        if ai_response.get("usage", {}).get("total_tokens"):
            conversation.total_tokens = (conversation.total_tokens or 0) + ai_response["usage"]["total_tokens"]
        
        self.db.commit()
        
        # ç”Ÿæˆå“åº”
        response = {
            "id": str(assistant_message.id),
            "conversation_id": str(conversation.id),
            "content": ai_response["content"],
            "model": model,
            "created_at": assistant_message.created_at.isoformat(),
            "metadata": assistant_message.message_data or {},
            "usage": ai_response.get("usage", {})
        }

        # å¦‚æœå¯ç”¨äº†åç»­é—®é¢˜ç”Ÿæˆ
        if user.preferences and user.preferences.get("FOLLOW_UP", True):
            follow_up_questions = await self._generate_follow_up_questions(
                ai_response["content"], 
                user.language or "en",
                model
            )
            if follow_up_questions:
                response["follow_up_questions"] = follow_up_questions

        logger.info(f"Returning response: {response}")
        return response

    
    async def stream_message(
        self,
        user_id: UUID,
        message: str,
        model: Optional[str] = None,
        conversation_id: Optional[str] = None,
        system_prompt: Optional[str] = None,
        attachments: Optional[List[str]] = None
    ) -> AsyncGenerator[StreamChunk, None]:
        """æµå¼å¤„ç†æ¶ˆæ¯"""
        
        # è·å–ç”¨æˆ·å’Œä¼šè¯
        user = self.db.query(User).filter(User.id == user_id).first()
        if not user:
            raise ValueError("ç”¨æˆ·ä¸å­˜åœ¨")
        
        model = model or user.preferred_model or settings.DEFAULT_MODEL
        
        # æ£€æµ‹æ˜¯å¦æ˜¯ä»£ç ç”Ÿæˆè¯·æ±‚
        is_code_generation, script_type = self.ai_code_service.detect_code_generation_intent(message)
        
        if is_code_generation:
            # å¯¹äºä»£ç ç”Ÿæˆè¯·æ±‚ï¼Œä½¿ç”¨éæµå¼å¤„ç†ï¼ˆå› ä¸ºéœ€è¦å®Œæ•´åˆ†æï¼‰
            result = await self.process_message(
                user_id=user_id,
                message=message,
                model=model,
                conversation_id=conversation_id,
                system_prompt=system_prompt,
                attachments=attachments
            )
            
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º
            yield StreamChunk(
                content=result["content"],
                type="text",
                metadata=result.get("metadata", {})
            )
            
            yield StreamChunk(
                content="",
                type="complete",
                metadata={
                    "final_content": result["content"],
                    "code_extraction": result.get("code_extraction"),
                    "cron_setup": result.get("cron_setup")
                }
            )
            return
        
        # åŸæœ‰çš„æµå¼å¤„ç†é€»è¾‘
        if conversation_id:
            try:
                conv_uuid = UUID(conversation_id)
                conversation = self._get_conversation(user_id, conv_uuid)
            except ValueError:
                conversation = None
                
            if not conversation:
                conversation = self._create_conversation(user_id, model, system_prompt)
        else:
            conversation = self._create_conversation(user_id, model, system_prompt)
        
        # å¤„ç†é™„ä»¶
        if attachments:
            message = await self._process_attachments(attachments, message)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_message = ChatMessage(
            session_id=conversation.id,
            role="user",
            content=message,
            attachments=attachments or []
        )
        self.db.add(user_message)
        self.db.commit()
        
        # è·å–å†å²å’Œé…ç½®
        pass_history = user.preferences.get("PASS_HISTORY", 3) if user.preferences else 3
        history = self._get_conversation_history(
            conversation.id,
            limit=pass_history if pass_history > 0 else 0
        )
        
        # ç³»ç»Ÿæç¤ºè¯
        if model and "claude" in model.lower():
            final_system_prompt = system_prompt or user.claude_system_prompt or ""
        else:
            final_system_prompt = system_prompt or user.system_prompt or ""
        
        # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å ä½ç¬¦
        assistant_message = ChatMessage(
            session_id=conversation.id,
            role="assistant",
            content="",
            model=model
        )
        self.db.add(assistant_message)
        self.db.commit()
        
        # æµå¼å“åº”å˜é‡
        full_response = ""
        frequency_modification = self._get_frequency_modification(model, str(conversation.id))
        modify_time = 0
        
        try:
            # å‘é€å¼€å§‹è¾“å…¥çŠ¶æ€
            yield StreamChunk(
                content="",
                type="typing_start",
                metadata={"message_id": str(assistant_message.id)}
            )
            
            # æµå¼è·å–AIå“åº”
            async for chunk in self.ai_engine.stream_completion(
                messages=history,
                model=model,
                system_prompt=final_system_prompt,
                temperature=0.7,
                plugins=self._get_enabled_plugins(user),
                user_id=str(user_id),
                api_key=self._get_api_key(user, model),
                api_url=self._get_api_url(user, model)
            ):
                # å¤„ç†æœç´¢é˜¶æ®µæ¶ˆæ¯
                if chunk.type == "search_stage":
                    yield StreamChunk(
                        content=chunk.content,
                        type="stage",
                        metadata=chunk.metadata
                    )
                    continue
                
                full_response += chunk.content
                
                # å¤„ç†Markdownæ ¼å¼
                formatted_response = self._format_response(full_response, model)
                
                # æ›´æ–°ç¼“å­˜
                await self._update_streaming_cache(
                    str(conversation.id),
                    str(assistant_message.id),
                    formatted_response
                )
                
                # å®šæœŸå‘é€æ›´æ–°
                modify_time += 1
                if modify_time % frequency_modification == 0:
                    yield StreamChunk(
                        content=chunk.content,
                        type="text",
                        metadata={
                            "message_id": str(assistant_message.id),
                            "conversation_id": str(conversation.id),
                            "formatted": formatted_response
                        }
                    )
                else:
                    # ä»…å‘é€å¢é‡å†…å®¹
                    yield StreamChunk(
                        content=chunk.content,
                        type="text_delta",
                        metadata={"message_id": str(assistant_message.id)}
                    )
            
            # ä¿å­˜å®Œæ•´å“åº”
            assistant_message.content = full_response
            assistant_message.message_data = {
                "model": model,
                "stream_completed": True
            }
            
            # è‡ªåŠ¨æå–ä»£ç 
            user_preferences = user.preferences or {}
            if user_preferences.get("auto_extract_code", True):
                try:
                    code_result = await self.code_service.process_ai_response_for_code(
                        ai_response=full_response,
                        user_id=str(user_id),
                        conversation_id=str(conversation.id),
                        auto_save=user_preferences.get("auto_save_code", True)
                    )
                    
                    if code_result["has_code"] and code_result["saved_blocks"] > 0:
                        notification = f"\n\nğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ {code_result['saved_blocks']} ä¸ªå¯æ‰§è¡Œä»£ç å—ã€‚"
                        assistant_message.content += notification
                        full_response += notification
                        
                        yield StreamChunk(
                            content=notification,
                            type="text",
                            metadata={"code_extraction": code_result}
                        )
                except Exception as e:
                    logger.error(f"Code extraction failed: {e}")
            
            conversation.updated_at = datetime.utcnow()
            conversation.message_count = (conversation.message_count or 0) + 2
            self.db.commit()
            
            # å‘é€å®Œæˆä¿¡å·
            yield StreamChunk(
                content="",
                type="complete",
                metadata={
                    "message_id": str(assistant_message.id),
                    "final_content": full_response
                }
            )
            
            # æ¸…ç†ç¼“å­˜
            await self._clear_streaming_cache(str(conversation.id), str(assistant_message.id))
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            self.db.delete(assistant_message)
            self.db.commit()
            
            yield StreamChunk(
                content=str(e),
                type="error",
                metadata={"error": True, "message": str(e)}
            )
    
    # ... å…¶ä½™æ–¹æ³•ä¿æŒä¸å˜ ...
    
    def _is_code_generation_request(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯ä»£ç ç”Ÿæˆè¯·æ±‚ï¼ˆæ—§æ–¹æ³•ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        keywords = ["å†™ä¸€ä¸ª", "åˆ›å»ºä¸€ä¸ª", "ç”Ÿæˆä¸€ä¸ª", "write a", "create a", "generate a", 
                   "è„šæœ¬", "script", "ä»£ç ", "code", "ç¨‹åº", "program"]
        return any(keyword in message.lower() for keyword in keywords)
    
    def _get_code_generation_prompt(self) -> str:
        """è·å–ä»£ç ç”Ÿæˆæç¤ºè¯"""
        return """When generating code, please:
1. Provide complete, executable code
2. Include proper error handling
3. Add helpful comments
4. Use safe coding practices
5. Include usage instructions

For Python scripts, use proper shebang and if __name__ == "__main__" structure.
For Bash scripts, use proper shebang and set -euo pipefail for safety."""
    
    # ... å…¶ä½™è¾…åŠ©æ–¹æ³•ä¿æŒä¸å˜ ...
    
    async def reset_conversation(
        self,
        user_id: UUID,
        conversation_id: str,
        system_prompt: Optional[str] = None
    ):
        """é‡ç½®ä¼šè¯"""
        try:
            conv_uuid = UUID(conversation_id)
        except ValueError:
            raise ValueError("æ— æ•ˆçš„ä¼šè¯ID")
            
        conversation = self._get_conversation(user_id, conv_uuid)
        if not conversation:
            raise ValueError("ä¼šè¯ä¸å­˜åœ¨")
        
        # åˆ é™¤æ‰€æœ‰æ¶ˆæ¯
        self.db.query(ChatMessage).filter(
            ChatMessage.session_id == conversation.id
        ).delete()
        
        # æ›´æ–°ä¼šè¯ä¿¡æ¯
        conversation.message_count = 0
        conversation.total_tokens = 0
        conversation.updated_at = datetime.utcnow()
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
        if system_prompt:
            if not conversation.config:
                conversation.config = {}
            conversation.config["system_prompt"] = system_prompt
        
        self.db.commit()
        
    async def get_conversation_history(
        self,
        user_id: UUID,
        conversation_id: str,
        limit: int = 50,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """è·å–ä¼šè¯å†å²"""
        try:
            conv_uuid = UUID(conversation_id)
        except ValueError:
            raise ValueError("æ— æ•ˆçš„ä¼šè¯ID")
            
        conversation = self._get_conversation(user_id, conv_uuid)
        if not conversation:
            raise ValueError("ä¼šè¯ä¸å­˜åœ¨")
        
        messages = self.db.query(ChatMessage).filter(
            and_(
                ChatMessage.session_id == conversation.id,
                ChatMessage.is_deleted == False
            )
        ).order_by(ChatMessage.created_at.desc()).offset(offset).limit(limit).all()
        
        return [
            {
                "id": str(msg.id),
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at.isoformat(),
                "edited_at": msg.edited_at.isoformat() if msg.edited_at else None,
                "attachments": msg.attachments,
                "metadata": msg.message_data,
                "model": msg.model
            }
            for msg in reversed(messages)
        ]
    
    async def delete_message(self, user_id: UUID, message_id: str):
        """åˆ é™¤æ¶ˆæ¯"""
        try:
            msg_uuid = UUID(message_id)
        except ValueError:
            raise ValueError("æ— æ•ˆçš„æ¶ˆæ¯ID")
            
        message = self.db.query(ChatMessage).join(ChatSession).filter(
            and_(
                ChatMessage.id == msg_uuid,
                ChatSession.user_id == user_id
            )
        ).first()
        
        if not message:
            raise ValueError("æ¶ˆæ¯ä¸å­˜åœ¨æˆ–æ— æƒåˆ é™¤")
        
        message.is_deleted = True
        message.deleted_at = datetime.utcnow()
        self.db.commit()
    
    async def edit_message(
        self,
        user_id: UUID,
        message_id: str,
        new_content: str
    ) -> Dict[str, Any]:
        """ç¼–è¾‘æ¶ˆæ¯"""
        try:
            msg_uuid = UUID(message_id)
        except ValueError:
            raise ValueError("æ— æ•ˆçš„æ¶ˆæ¯ID")
            
        message = self.db.query(ChatMessage).join(ChatSession).filter(
            and_(
                ChatMessage.id == msg_uuid,
                ChatSession.user_id == user_id
            )
        ).first()
        
        if not message:
            raise ValueError("æ¶ˆæ¯ä¸å­˜åœ¨æˆ–æ— æƒç¼–è¾‘")
        
        message.content = new_content
        message.edited_at = datetime.utcnow()
        message.is_edited = True
        self.db.commit()
        
        return {
            "id": str(message.id),
            "content": message.content,
            "edited_at": message.edited_at.isoformat()
        }
    
    # è¾…åŠ©æ–¹æ³•
    def _get_conversation(self, user_id: UUID, conversation_id: UUID) -> Optional[ChatSession]:
        """è·å–ä¼šè¯"""
        return self.db.query(ChatSession).filter(
            and_(
                ChatSession.id == conversation_id,
                ChatSession.user_id == user_id,
                ChatSession.is_active == True
            )
        ).first()
    
    def _create_conversation(
        self,
        user_id: UUID,
        model: str,
        system_prompt: Optional[str] = None
    ) -> ChatSession:
        """åˆ›å»ºæ–°ä¼šè¯"""
        conversation = ChatSession(
            user_id=user_id,
            title=f"New Chat - {datetime.utcnow().strftime('%Y-%m-%d %H:%M')}",
            config={
                "model": model,
                "system_prompt": system_prompt
            } if system_prompt else {"model": model}
        )
        self.db.add(conversation)
        self.db.commit()
        return conversation
    
    def _get_conversation_history(
        self,
        conversation_id: UUID,
        limit: int = 50
    ) -> List[Dict[str, str]]:
        """è·å–ä¼šè¯å†å²ç”¨äºAI"""
        if limit == 0:
            return []
        
        messages = self.db.query(ChatMessage).filter(
            and_(
                ChatMessage.session_id == conversation_id,
                ChatMessage.is_deleted == False
            )
        ).order_by(ChatMessage.created_at.desc()).limit(limit).all()
        
        return [
            {"role": msg.role, "content": msg.content}
            for msg in reversed(messages)
        ]
    
    def _get_enabled_plugins(self, user: User) -> Dict[str, bool]:
        """è·å–ç”¨æˆ·å¯ç”¨çš„æ’ä»¶"""
        if not user.plugins:
            return {}
            
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦æ”¯æŒè¯¥æ’ä»¶
        available_plugins = getattr(settings, 'AVAILABLE_PLUGINS', {})
        
        return {
            plugin: enabled
            for plugin, enabled in user.plugins.items()
            if enabled and available_plugins.get(plugin, False)
        }
    
    def _get_api_key(self, user: User, model: str) -> Optional[str]:
        """è·å–APIå¯†é’¥"""
        if not model:
            return None
            
        # é¦–å…ˆå°è¯•ç”¨æˆ·è‡ªå®šä¹‰å¯†é’¥
        provider = self._get_model_provider(model)
        if provider and user.api_keys and user.api_keys.get(provider):
            return user.api_keys[provider]
        
        # ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å¯†é’¥
        try:
            from app.config import get_api_key_for_model
            return get_api_key_for_model(model)
        except:
            return None
    
    def _get_api_url(self, user: User, model: str) -> Optional[str]:
        """è·å–API URL"""
        if not model:
            return None
            
        provider = self._get_model_provider(model)
        if provider and user.api_urls and user.api_urls.get(provider):
            return user.api_urls[provider]
        
        try:
            from app.config import get_api_base_for_model
            return get_api_base_for_model(model)
        except:
            return None
    
    def _get_model_provider(self, model: str) -> Optional[str]:
        """è·å–æ¨¡å‹æä¾›å•†"""
        if not model:
            return None
            
        model_lower = model.lower()
        if "gpt" in model_lower:
            return "openai"
        elif "claude" in model_lower:
            return "anthropic"
        elif "gemini" in model_lower:
            return "google"
        elif "doubao" in model_lower:
            return "doubao"
        else:
            return "custom"
    
    async def _process_attachments(
        self,
        attachment_ids: List[str],
        message: str
    ) -> str:
        """å¤„ç†é™„ä»¶å¹¶å°†å†…å®¹æ·»åŠ åˆ°æ¶ˆæ¯ä¸­"""
        from app.models.file import File
        
        for file_id in attachment_ids:
            try:
                file_uuid = UUID(file_id)
                file = self.db.query(File).filter(File.id == file_uuid).first()
                if file and file.extracted_text:
                    message = f"{file.extracted_text}\n\n{message}"
            except ValueError:
                continue
        
        return message
    
    def _format_response(self, response: str, model: str) -> str:
        """æ ¼å¼åŒ–å“åº”ï¼ˆå¤„ç†Markdownç­‰ï¼‰"""
        # å¤„ç†æœªé—­åˆçš„ä»£ç å—
        if response.count("```") % 2 != 0:
            response += "\n```"
        
        # Claudeç‰¹æ®Šå¤„ç†
        if model and "claude" in model.lower():
            response = self._claude_format(response)
        
        return response
    
    def _claude_format(self, text: str) -> str:
        """Claudeå“åº”æ ¼å¼åŒ–"""
        # å®ç°Claudeç‰¹å®šçš„æ ¼å¼åŒ–é€»è¾‘
        return text
    
    def _get_frequency_modification(self, model: str, conversation_id: str) -> int:
        """è·å–æ›´æ–°é¢‘ç‡"""
        if "gpt-4" in model.lower():
            return 25
        elif "gemini" in model.lower():
            return 1
        elif conversation_id.startswith("group_"):
            return 35
        else:
            return 20
    
    async def _generate_follow_up_questions(
        self,
        response: str,
        language: str,
        model: str
    ) -> List[str]:
        """ç”Ÿæˆåç»­é—®é¢˜"""
        prompt = (
            f"Based on the following response, generate 3 relevant follow-up questions "
            f"in {language}. Only output the questions, one per line.\n\n"
            f"Response: {response[:1000]}"
        )
        
        try:
            result = await self.ai_engine.get_completion(
                messages=[{"role": "user", "content": prompt}],
                model=model,
                temperature=0.7,
                max_tokens=200
            )
            
            questions = result["content"].strip().split('\n')
            return [q.strip() for q in questions if q.strip()][:3]
        except:
            return []
    
    async def _update_streaming_cache(
        self,
        conversation_id: str,
        message_id: str,
        content: str
    ):
        """æ›´æ–°æµå¼å“åº”ç¼“å­˜"""
        key = f"stream:{conversation_id}:{message_id}"
        await self.redis.setex(key, 300, content)
    
    async def _clear_streaming_cache(
        self,
        conversation_id: str,
        message_id: str
    ):
        """æ¸…ç†æµå¼å“åº”ç¼“å­˜"""
        key = f"stream:{conversation_id}:{message_id}"
        await self.redis.delete(key)
    
    async def _clear_conversation_cache(self, conversation_id: str):
        """æ¸…ç†ä¼šè¯ç›¸å…³çš„æ‰€æœ‰ç¼“å­˜"""
        pattern = f"stream:{conversation_id}:*"
        cursor = 0
        while True:
            cursor, keys = await self.redis.scan(cursor, match=pattern)
            if keys:
                await self.redis.delete(*keys)
            if cursor == 0:
                break


class WebSocketChatService(ChatService):
    """WebSocketèŠå¤©æœåŠ¡"""
    
    async def handle_websocket_message(
        self,
        websocket: WebSocket,
        user_id: UUID,
        message: Dict[str, Any]
    ):
        """å¤„ç†WebSocketæ¶ˆæ¯"""
        action = message.get("action")
        
        if action == "send_message":
            await self._handle_send_message(websocket, user_id, message)
        elif action == "edit_message":
            await self._handle_edit_message(websocket, user_id, message)
        elif action == "delete_message":
            await self._handle_delete_message(websocket, user_id, message)
        elif action == "typing":
            await self._handle_typing_indicator(websocket, user_id, message)
    
    async def _handle_send_message(
        self,
        websocket: WebSocket,
        user_id: UUID,
        message: Dict[str, Any]
    ):
        """å¤„ç†å‘é€æ¶ˆæ¯"""
        conversation_id = message.get("conversation_id")
        content = message.get("content")
        model = message.get("model")
        
        # å‘é€"æ­£åœ¨è¾“å…¥"çŠ¶æ€
        await websocket.send_json({
            "type": "typing",
            "data": {"status": "start"}
        })
        
        try:
            # æµå¼å¤„ç†æ¶ˆæ¯
            async for chunk in self.stream_message(
                user_id=user_id,
                message=content,
                model=model,
                conversation_id=conversation_id
            ):
                await websocket.send_json({
                    "type": "stream",
                    "data": {
                        "content": chunk.content,
                        "chunk_type": chunk.type,
                        "metadata": chunk.metadata
                    }
                })
            
            # å‘é€å®Œæˆä¿¡å·
            await websocket.send_json({
                "type": "complete",
                "data": {"status": "success"}
            })
            
        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "data": {"error": str(e)}
            })
        finally:
            # åœæ­¢"æ­£åœ¨è¾“å…¥"çŠ¶æ€
            await websocket.send_json({
                "type": "typing",
                "data": {"status": "stop"}
            })
    
    async def _handle_edit_message(
        self,
        websocket: WebSocket,
        user_id: UUID,
        message: Dict[str, Any]
    ):
        """å¤„ç†ç¼–è¾‘æ¶ˆæ¯"""
        message_id = message.get("message_id")
        new_content = message.get("content")
        
        try:
            updated_message = await self.edit_message(
                user_id=user_id,
                message_id=message_id,
                new_content=new_content
            )
            
            await websocket.send_json({
                "type": "message_edited",
                "data": updated_message
            })
        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "data": {"error": str(e)}
            })
    
    async def _handle_delete_message(
        self,
        websocket: WebSocket,
        user_id: UUID,
        message: Dict[str, Any]
    ):
        """å¤„ç†åˆ é™¤æ¶ˆæ¯"""
        message_id = message.get("message_id")
        
        try:
            await self.delete_message(user_id, message_id)
            
            await websocket.send_json({
                "type": "message_deleted",
                "data": {"message_id": message_id}
            })
        except Exception as e:
            await websocket.send_json({
                "type": "error",
                "data": {"error": str(e)}
            })
    
    async def _handle_typing_indicator(
        self,
        websocket: WebSocket,
        user_id: UUID,
        message: Dict[str, Any]
    ):
        """å¤„ç†è¾“å…¥æŒ‡ç¤ºå™¨"""
        conversation_id = message.get("conversation_id")
        is_typing = message.get("is_typing", False)
        
        # å¹¿æ’­ç»™ä¼šè¯ä¸­çš„å…¶ä»–ç”¨æˆ·ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªå›æ˜¾ç»™å‘é€è€…
        await websocket.send_json({
            "type": "typing_indicator",
            "data": {
                "user_id": str(user_id),
                "conversation_id": conversation_id,
                "is_typing": is_typing
            }
        })
    
    async def get_user_by_username(self, username: str) -> Optional[User]:
        """æ ¹æ®ç”¨æˆ·åè·å–ç”¨æˆ·"""
        return self.db.query(User).filter(User.username == username).first()